# AI Model Configuration Guide

**ç‰ˆæœ¬:** 1.0  
**æ›´æ–°:** 2025-07-09  
**çŠ¶æ€:** ç³»ç»Ÿé…ç½®æŒ‡å—

---

## 1. å½“å‰AIæ¨¡å‹é…ç½®

### 1.1 é»˜è®¤é…ç½®

HELIXç³»ç»Ÿå·²é…ç½®ä¸ºä½¿ç”¨**Google Gemini 2.5 Flash**ä½œä¸ºé»˜è®¤AIæ¨¡å‹ï¼š

```bash
# ç¯å¢ƒå˜é‡é…ç½®
DEFAULT_AI_PROVIDER=gemini
DEFAULT_AI_MODEL=gemini-2.5-flash
```

### 1.2 æ¨¡å‹ç‰¹æ€§

**Gemini 2.5 Flashä¼˜åŠ¿ï¼š**
- ğŸš€ **é«˜é€Ÿå“åº”**: é’ˆå¯¹å¿«é€Ÿæ¨ç†ä¼˜åŒ–
- ğŸ¯ **å¤šæ¨¡æ€æ”¯æŒ**: æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€ä»£ç ç­‰å¤šç§è¾“å…¥æ ¼å¼
- ğŸ’¡ **æ™ºèƒ½ç†è§£**: å…·å¤‡å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›
- ğŸ”§ **ç»“æ„åŒ–è¾“å‡º**: ç‰¹åˆ«é€‚åˆç”ŸæˆJSONæ ¼å¼çš„ç»“æ„åŒ–å“åº”

## 2. é…ç½®æ–‡ä»¶ä½ç½®

### 2.1 ç¯å¢ƒé…ç½®

```bash
# ä¸»é…ç½®æ–‡ä»¶
/home/canoezhang/Projects/aiagent/.env

# æ¨¡æ¿æ–‡ä»¶
/home/canoezhang/Projects/aiagent/.env.example
```

### 2.2 ä»£ç é…ç½®

```bash
# AIå®¢æˆ·ç«¯å·¥å‚
/home/canoezhang/Projects/aiagent/src/ai_clients/client_factory.py

# Geminiå®¢æˆ·ç«¯å®ç°
/home/canoezhang/Projects/aiagent/src/ai_clients/gemini_client.py
```

## 3. ä½¿ç”¨ç¤ºä¾‹

### 3.1 åœ¨Agentä¸­ä½¿ç”¨

```python
# æ ‡å‡†Agentå®ç°
from ai_clients.client_factory import AIClientFactory

class YourAgent(BaseAgent):
    async def _generate_with_ai(self, artifacts, system_prompt):
        # è‡ªåŠ¨ä½¿ç”¨é…ç½®çš„Gemini 2.5 Flash
        ai_client = AIClientFactory.create_client()
        
        response = await ai_client.generate_response(
            system_prompt=system_prompt,
            user_input=self._prepare_input_materials(artifacts),
            temperature=0.7,
            max_tokens=3000
        )
        
        return self._parse_ai_response(response["content"], response)
```

### 3.2 æ˜¾å¼æŒ‡å®šæ¨¡å‹

```python
# æ˜¾å¼æŒ‡å®šGemini 2.5 Flash
ai_client = AIClientFactory.create_client(
    provider="gemini",
    model="gemini-2.5-flash"
)
```

## 4. é…ç½®éªŒè¯

### 4.1 è¿è¡Œé…ç½®æµ‹è¯•

```bash
# éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®
source venv/bin/activate
python test_gemini_config.py
```

### 4.2 é¢„æœŸè¾“å‡º

```
ğŸ‰ SUCCESS: System is correctly configured to use Gemini 2.5 Flash!
   - Default provider: gemini
   - Default model: gemini-2.5-flash
   - All components aligned
```

## 5. æ”¯æŒçš„AIæä¾›å•†

### 5.1 å¯ç”¨æä¾›å•†

| æä¾›å•† | é»˜è®¤æ¨¡å‹ | æè¿° |
|--------|----------|------|
| **gemini** | gemini-2.5-flash | Google Gemini 2.5 Flash - å¿«é€Ÿé«˜æ•ˆçš„å¤šæ¨¡æ€AIæ¨¡å‹ |
| deepseek | deepseek-chat | DeepSeek AI - å…·æœ‰å¼ºæ¨ç†èƒ½åŠ›çš„å¯¹è¯AI |

### 5.2 æä¾›å•†é…ç½®

```bash
# Geminié…ç½®
GEMINI_API_KEY=your_gemini_api_key_here

# DeepSeeké…ç½®
DEEPSEEK_API_KEY=your_deepseek_api_key_here
```

## 6. æ•…éšœæ’æŸ¥

### 6.1 å¸¸è§é—®é¢˜

**é—®é¢˜1: æ¨¡å‹å“åº”æ…¢**
- è§£å†³æ–¹æ¡ˆ: Gemini 2.5 Flashå·²ä¼˜åŒ–ä¸ºé«˜é€Ÿå“åº”
- æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…é¢

**é—®é¢˜2: APIå¯†é’¥é”™è¯¯**
- è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥`.env`æ–‡ä»¶ä¸­çš„`GEMINI_API_KEY`é…ç½®
- ç¡®ä¿APIå¯†é’¥æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿé…é¢

**é—®é¢˜3: æ¨¡å‹ä¸å­˜åœ¨**
- è§£å†³æ–¹æ¡ˆ: ç¡®è®¤æ¨¡å‹åç§°ä¸º`gemini-2.5-flash`
- æ£€æŸ¥Google AI APIæ˜¯å¦æ”¯æŒè¯¥æ¨¡å‹

### 6.2 è°ƒè¯•å·¥å…·

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $DEFAULT_AI_PROVIDER
echo $DEFAULT_AI_MODEL

# æµ‹è¯•APIè¿æ¥
python -c "
import asyncio
from src.ai_clients.client_factory import AIClientFactory
from dotenv import load_dotenv
load_dotenv()

async def test():
    client = AIClientFactory.create_client()
    print(f'Provider: {client.__class__.__name__}')
    print(f'Model: {client.model_name}')
    
    # æµ‹è¯•APIè°ƒç”¨
    response = await client.generate_response(
        system_prompt='You are a helpful assistant.',
        user_input='Hello, please respond with \"Configuration working!\"',
        temperature=0.1,
        max_tokens=50
    )
    print(f'Response: {response[\"content\"]}')

asyncio.run(test())
"
```

## 7. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 7.1 æç¤ºè¯ä¼˜åŒ–

```python
# é’ˆå¯¹Gemini 2.5 Flashä¼˜åŒ–çš„æç¤ºè¯æ¨¡å¼
enhanced_prompt = f"""{system_prompt}

CRITICAL: You must respond with VALID JSON only. Do not include any text before or after the JSON.
The JSON must follow this exact structure:

{schema_template}

Remember: Follow your internal thinking process, but output ONLY the final JSON result."""
```

### 7.2 å‚æ•°è°ƒä¼˜

```python
# æ¨èçš„Gemini 2.5 Flashå‚æ•°
response = await ai_client.generate_response(
    system_prompt=enhanced_prompt,
    user_input=input_materials,
    temperature=0.7,        # å¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§
    max_tokens=3000,        # è¶³å¤Ÿçš„è¾“å‡ºé•¿åº¦
    top_p=0.95,            # é€‚å½“çš„æ ¸é‡‡æ ·
    top_k=64               # åˆé€‚çš„top-ké‡‡æ ·
)
```

## 8. ç›‘æ§å’Œæ—¥å¿—

### 8.1 æ—¥å¿—æ ¼å¼

```python
# æ ‡å‡†æ—¥å¿—è®°å½•
logger.info("AI client created successfully", 
           provider="gemini", 
           model="gemini-2.5-flash")

logger.info("Gemini response received successfully",
           content_length=len(content),
           tokens_used=usage["total_tokens"])
```

### 8.2 ç›‘æ§æŒ‡æ ‡

- **å“åº”æ—¶é—´**: é€šå¸¸ < 2ç§’
- **Tokenä½¿ç”¨é‡**: æ ¹æ®è¾“å…¥å¤æ‚åº¦è‡ªåŠ¨è°ƒæ•´
- **æˆåŠŸç‡**: ç›®æ ‡ > 95%
- **é”™è¯¯ç‡**: ä¸»è¦ç›‘æ§APIé™æµå’Œè®¤è¯é”™è¯¯

---

## ğŸ“ æ€»ç»“

HELIXç³»ç»Ÿç°å·²å®Œå…¨é…ç½®ä¸ºä½¿ç”¨Google Gemini 2.5 Flashæ¨¡å‹ï¼Œæä¾›å¿«é€Ÿã€é«˜æ•ˆçš„AIå“åº”ã€‚æ‰€æœ‰Agentå°†è‡ªåŠ¨ä½¿ç”¨è¿™ä¸ªé…ç½®ï¼Œæ— éœ€é¢å¤–ä»£ç ä¿®æ”¹ã€‚

**å…³é”®é…ç½®ç‚¹:**
1. âœ… é»˜è®¤æä¾›å•†: gemini
2. âœ… é»˜è®¤æ¨¡å‹: gemini-2.5-flash  
3. âœ… æ‰€æœ‰Agentè‡ªåŠ¨ä½¿ç”¨
4. âœ… æ”¯æŒç»“æ„åŒ–JSONè¾“å‡º
5. âœ… ä¼˜åŒ–çš„æç¤ºè¯æ¨¡å¼

å¦‚éœ€æ›´æ”¹AIæ¨¡å‹ï¼Œåªéœ€ä¿®æ”¹`.env`æ–‡ä»¶ä¸­çš„ç›¸åº”é…ç½®å³å¯ã€‚